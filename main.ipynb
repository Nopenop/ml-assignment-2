{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST data training\n",
    "- For this assignment I plan on using:\n",
    "     - Random Forrest\n",
    "     - K-nearest neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn as skl, sklearn.datasets as skds\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fetch the dataset from https://www.openml.org/\n",
    "mnist = skds.fetch_openml('mnist_784', as_frame=False, parser='auto')\n",
    "\n",
    "# the returned if of type sklearn.utils.Bunch\n",
    "# this is a dictionary whose keys can also be accessed as attributes\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " 'target': array(['5', '0', '4', ..., '4', '5', '6'], dtype=object),\n",
       " 'frame': None,\n",
       " 'categories': {'class': ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']},\n",
       " 'feature_names': ['pixel1',\n",
       "  'pixel2',\n",
       "  'pixel3',\n",
       "  'pixel4',\n",
       "  'pixel5',\n",
       "  'pixel6',\n",
       "  'pixel7',\n",
       "  'pixel8',\n",
       "  'pixel9',\n",
       "  'pixel10',\n",
       "  'pixel11',\n",
       "  'pixel12',\n",
       "  'pixel13',\n",
       "  'pixel14',\n",
       "  'pixel15',\n",
       "  'pixel16',\n",
       "  'pixel17',\n",
       "  'pixel18',\n",
       "  'pixel19',\n",
       "  'pixel20',\n",
       "  'pixel21',\n",
       "  'pixel22',\n",
       "  'pixel23',\n",
       "  'pixel24',\n",
       "  'pixel25',\n",
       "  'pixel26',\n",
       "  'pixel27',\n",
       "  'pixel28',\n",
       "  'pixel29',\n",
       "  'pixel30',\n",
       "  'pixel31',\n",
       "  'pixel32',\n",
       "  'pixel33',\n",
       "  'pixel34',\n",
       "  'pixel35',\n",
       "  'pixel36',\n",
       "  'pixel37',\n",
       "  'pixel38',\n",
       "  'pixel39',\n",
       "  'pixel40',\n",
       "  'pixel41',\n",
       "  'pixel42',\n",
       "  'pixel43',\n",
       "  'pixel44',\n",
       "  'pixel45',\n",
       "  'pixel46',\n",
       "  'pixel47',\n",
       "  'pixel48',\n",
       "  'pixel49',\n",
       "  'pixel50',\n",
       "  'pixel51',\n",
       "  'pixel52',\n",
       "  'pixel53',\n",
       "  'pixel54',\n",
       "  'pixel55',\n",
       "  'pixel56',\n",
       "  'pixel57',\n",
       "  'pixel58',\n",
       "  'pixel59',\n",
       "  'pixel60',\n",
       "  'pixel61',\n",
       "  'pixel62',\n",
       "  'pixel63',\n",
       "  'pixel64',\n",
       "  'pixel65',\n",
       "  'pixel66',\n",
       "  'pixel67',\n",
       "  'pixel68',\n",
       "  'pixel69',\n",
       "  'pixel70',\n",
       "  'pixel71',\n",
       "  'pixel72',\n",
       "  'pixel73',\n",
       "  'pixel74',\n",
       "  'pixel75',\n",
       "  'pixel76',\n",
       "  'pixel77',\n",
       "  'pixel78',\n",
       "  'pixel79',\n",
       "  'pixel80',\n",
       "  'pixel81',\n",
       "  'pixel82',\n",
       "  'pixel83',\n",
       "  'pixel84',\n",
       "  'pixel85',\n",
       "  'pixel86',\n",
       "  'pixel87',\n",
       "  'pixel88',\n",
       "  'pixel89',\n",
       "  'pixel90',\n",
       "  'pixel91',\n",
       "  'pixel92',\n",
       "  'pixel93',\n",
       "  'pixel94',\n",
       "  'pixel95',\n",
       "  'pixel96',\n",
       "  'pixel97',\n",
       "  'pixel98',\n",
       "  'pixel99',\n",
       "  'pixel100',\n",
       "  'pixel101',\n",
       "  'pixel102',\n",
       "  'pixel103',\n",
       "  'pixel104',\n",
       "  'pixel105',\n",
       "  'pixel106',\n",
       "  'pixel107',\n",
       "  'pixel108',\n",
       "  'pixel109',\n",
       "  'pixel110',\n",
       "  'pixel111',\n",
       "  'pixel112',\n",
       "  'pixel113',\n",
       "  'pixel114',\n",
       "  'pixel115',\n",
       "  'pixel116',\n",
       "  'pixel117',\n",
       "  'pixel118',\n",
       "  'pixel119',\n",
       "  'pixel120',\n",
       "  'pixel121',\n",
       "  'pixel122',\n",
       "  'pixel123',\n",
       "  'pixel124',\n",
       "  'pixel125',\n",
       "  'pixel126',\n",
       "  'pixel127',\n",
       "  'pixel128',\n",
       "  'pixel129',\n",
       "  'pixel130',\n",
       "  'pixel131',\n",
       "  'pixel132',\n",
       "  'pixel133',\n",
       "  'pixel134',\n",
       "  'pixel135',\n",
       "  'pixel136',\n",
       "  'pixel137',\n",
       "  'pixel138',\n",
       "  'pixel139',\n",
       "  'pixel140',\n",
       "  'pixel141',\n",
       "  'pixel142',\n",
       "  'pixel143',\n",
       "  'pixel144',\n",
       "  'pixel145',\n",
       "  'pixel146',\n",
       "  'pixel147',\n",
       "  'pixel148',\n",
       "  'pixel149',\n",
       "  'pixel150',\n",
       "  'pixel151',\n",
       "  'pixel152',\n",
       "  'pixel153',\n",
       "  'pixel154',\n",
       "  'pixel155',\n",
       "  'pixel156',\n",
       "  'pixel157',\n",
       "  'pixel158',\n",
       "  'pixel159',\n",
       "  'pixel160',\n",
       "  'pixel161',\n",
       "  'pixel162',\n",
       "  'pixel163',\n",
       "  'pixel164',\n",
       "  'pixel165',\n",
       "  'pixel166',\n",
       "  'pixel167',\n",
       "  'pixel168',\n",
       "  'pixel169',\n",
       "  'pixel170',\n",
       "  'pixel171',\n",
       "  'pixel172',\n",
       "  'pixel173',\n",
       "  'pixel174',\n",
       "  'pixel175',\n",
       "  'pixel176',\n",
       "  'pixel177',\n",
       "  'pixel178',\n",
       "  'pixel179',\n",
       "  'pixel180',\n",
       "  'pixel181',\n",
       "  'pixel182',\n",
       "  'pixel183',\n",
       "  'pixel184',\n",
       "  'pixel185',\n",
       "  'pixel186',\n",
       "  'pixel187',\n",
       "  'pixel188',\n",
       "  'pixel189',\n",
       "  'pixel190',\n",
       "  'pixel191',\n",
       "  'pixel192',\n",
       "  'pixel193',\n",
       "  'pixel194',\n",
       "  'pixel195',\n",
       "  'pixel196',\n",
       "  'pixel197',\n",
       "  'pixel198',\n",
       "  'pixel199',\n",
       "  'pixel200',\n",
       "  'pixel201',\n",
       "  'pixel202',\n",
       "  'pixel203',\n",
       "  'pixel204',\n",
       "  'pixel205',\n",
       "  'pixel206',\n",
       "  'pixel207',\n",
       "  'pixel208',\n",
       "  'pixel209',\n",
       "  'pixel210',\n",
       "  'pixel211',\n",
       "  'pixel212',\n",
       "  'pixel213',\n",
       "  'pixel214',\n",
       "  'pixel215',\n",
       "  'pixel216',\n",
       "  'pixel217',\n",
       "  'pixel218',\n",
       "  'pixel219',\n",
       "  'pixel220',\n",
       "  'pixel221',\n",
       "  'pixel222',\n",
       "  'pixel223',\n",
       "  'pixel224',\n",
       "  'pixel225',\n",
       "  'pixel226',\n",
       "  'pixel227',\n",
       "  'pixel228',\n",
       "  'pixel229',\n",
       "  'pixel230',\n",
       "  'pixel231',\n",
       "  'pixel232',\n",
       "  'pixel233',\n",
       "  'pixel234',\n",
       "  'pixel235',\n",
       "  'pixel236',\n",
       "  'pixel237',\n",
       "  'pixel238',\n",
       "  'pixel239',\n",
       "  'pixel240',\n",
       "  'pixel241',\n",
       "  'pixel242',\n",
       "  'pixel243',\n",
       "  'pixel244',\n",
       "  'pixel245',\n",
       "  'pixel246',\n",
       "  'pixel247',\n",
       "  'pixel248',\n",
       "  'pixel249',\n",
       "  'pixel250',\n",
       "  'pixel251',\n",
       "  'pixel252',\n",
       "  'pixel253',\n",
       "  'pixel254',\n",
       "  'pixel255',\n",
       "  'pixel256',\n",
       "  'pixel257',\n",
       "  'pixel258',\n",
       "  'pixel259',\n",
       "  'pixel260',\n",
       "  'pixel261',\n",
       "  'pixel262',\n",
       "  'pixel263',\n",
       "  'pixel264',\n",
       "  'pixel265',\n",
       "  'pixel266',\n",
       "  'pixel267',\n",
       "  'pixel268',\n",
       "  'pixel269',\n",
       "  'pixel270',\n",
       "  'pixel271',\n",
       "  'pixel272',\n",
       "  'pixel273',\n",
       "  'pixel274',\n",
       "  'pixel275',\n",
       "  'pixel276',\n",
       "  'pixel277',\n",
       "  'pixel278',\n",
       "  'pixel279',\n",
       "  'pixel280',\n",
       "  'pixel281',\n",
       "  'pixel282',\n",
       "  'pixel283',\n",
       "  'pixel284',\n",
       "  'pixel285',\n",
       "  'pixel286',\n",
       "  'pixel287',\n",
       "  'pixel288',\n",
       "  'pixel289',\n",
       "  'pixel290',\n",
       "  'pixel291',\n",
       "  'pixel292',\n",
       "  'pixel293',\n",
       "  'pixel294',\n",
       "  'pixel295',\n",
       "  'pixel296',\n",
       "  'pixel297',\n",
       "  'pixel298',\n",
       "  'pixel299',\n",
       "  'pixel300',\n",
       "  'pixel301',\n",
       "  'pixel302',\n",
       "  'pixel303',\n",
       "  'pixel304',\n",
       "  'pixel305',\n",
       "  'pixel306',\n",
       "  'pixel307',\n",
       "  'pixel308',\n",
       "  'pixel309',\n",
       "  'pixel310',\n",
       "  'pixel311',\n",
       "  'pixel312',\n",
       "  'pixel313',\n",
       "  'pixel314',\n",
       "  'pixel315',\n",
       "  'pixel316',\n",
       "  'pixel317',\n",
       "  'pixel318',\n",
       "  'pixel319',\n",
       "  'pixel320',\n",
       "  'pixel321',\n",
       "  'pixel322',\n",
       "  'pixel323',\n",
       "  'pixel324',\n",
       "  'pixel325',\n",
       "  'pixel326',\n",
       "  'pixel327',\n",
       "  'pixel328',\n",
       "  'pixel329',\n",
       "  'pixel330',\n",
       "  'pixel331',\n",
       "  'pixel332',\n",
       "  'pixel333',\n",
       "  'pixel334',\n",
       "  'pixel335',\n",
       "  'pixel336',\n",
       "  'pixel337',\n",
       "  'pixel338',\n",
       "  'pixel339',\n",
       "  'pixel340',\n",
       "  'pixel341',\n",
       "  'pixel342',\n",
       "  'pixel343',\n",
       "  'pixel344',\n",
       "  'pixel345',\n",
       "  'pixel346',\n",
       "  'pixel347',\n",
       "  'pixel348',\n",
       "  'pixel349',\n",
       "  'pixel350',\n",
       "  'pixel351',\n",
       "  'pixel352',\n",
       "  'pixel353',\n",
       "  'pixel354',\n",
       "  'pixel355',\n",
       "  'pixel356',\n",
       "  'pixel357',\n",
       "  'pixel358',\n",
       "  'pixel359',\n",
       "  'pixel360',\n",
       "  'pixel361',\n",
       "  'pixel362',\n",
       "  'pixel363',\n",
       "  'pixel364',\n",
       "  'pixel365',\n",
       "  'pixel366',\n",
       "  'pixel367',\n",
       "  'pixel368',\n",
       "  'pixel369',\n",
       "  'pixel370',\n",
       "  'pixel371',\n",
       "  'pixel372',\n",
       "  'pixel373',\n",
       "  'pixel374',\n",
       "  'pixel375',\n",
       "  'pixel376',\n",
       "  'pixel377',\n",
       "  'pixel378',\n",
       "  'pixel379',\n",
       "  'pixel380',\n",
       "  'pixel381',\n",
       "  'pixel382',\n",
       "  'pixel383',\n",
       "  'pixel384',\n",
       "  'pixel385',\n",
       "  'pixel386',\n",
       "  'pixel387',\n",
       "  'pixel388',\n",
       "  'pixel389',\n",
       "  'pixel390',\n",
       "  'pixel391',\n",
       "  'pixel392',\n",
       "  'pixel393',\n",
       "  'pixel394',\n",
       "  'pixel395',\n",
       "  'pixel396',\n",
       "  'pixel397',\n",
       "  'pixel398',\n",
       "  'pixel399',\n",
       "  'pixel400',\n",
       "  'pixel401',\n",
       "  'pixel402',\n",
       "  'pixel403',\n",
       "  'pixel404',\n",
       "  'pixel405',\n",
       "  'pixel406',\n",
       "  'pixel407',\n",
       "  'pixel408',\n",
       "  'pixel409',\n",
       "  'pixel410',\n",
       "  'pixel411',\n",
       "  'pixel412',\n",
       "  'pixel413',\n",
       "  'pixel414',\n",
       "  'pixel415',\n",
       "  'pixel416',\n",
       "  'pixel417',\n",
       "  'pixel418',\n",
       "  'pixel419',\n",
       "  'pixel420',\n",
       "  'pixel421',\n",
       "  'pixel422',\n",
       "  'pixel423',\n",
       "  'pixel424',\n",
       "  'pixel425',\n",
       "  'pixel426',\n",
       "  'pixel427',\n",
       "  'pixel428',\n",
       "  'pixel429',\n",
       "  'pixel430',\n",
       "  'pixel431',\n",
       "  'pixel432',\n",
       "  'pixel433',\n",
       "  'pixel434',\n",
       "  'pixel435',\n",
       "  'pixel436',\n",
       "  'pixel437',\n",
       "  'pixel438',\n",
       "  'pixel439',\n",
       "  'pixel440',\n",
       "  'pixel441',\n",
       "  'pixel442',\n",
       "  'pixel443',\n",
       "  'pixel444',\n",
       "  'pixel445',\n",
       "  'pixel446',\n",
       "  'pixel447',\n",
       "  'pixel448',\n",
       "  'pixel449',\n",
       "  'pixel450',\n",
       "  'pixel451',\n",
       "  'pixel452',\n",
       "  'pixel453',\n",
       "  'pixel454',\n",
       "  'pixel455',\n",
       "  'pixel456',\n",
       "  'pixel457',\n",
       "  'pixel458',\n",
       "  'pixel459',\n",
       "  'pixel460',\n",
       "  'pixel461',\n",
       "  'pixel462',\n",
       "  'pixel463',\n",
       "  'pixel464',\n",
       "  'pixel465',\n",
       "  'pixel466',\n",
       "  'pixel467',\n",
       "  'pixel468',\n",
       "  'pixel469',\n",
       "  'pixel470',\n",
       "  'pixel471',\n",
       "  'pixel472',\n",
       "  'pixel473',\n",
       "  'pixel474',\n",
       "  'pixel475',\n",
       "  'pixel476',\n",
       "  'pixel477',\n",
       "  'pixel478',\n",
       "  'pixel479',\n",
       "  'pixel480',\n",
       "  'pixel481',\n",
       "  'pixel482',\n",
       "  'pixel483',\n",
       "  'pixel484',\n",
       "  'pixel485',\n",
       "  'pixel486',\n",
       "  'pixel487',\n",
       "  'pixel488',\n",
       "  'pixel489',\n",
       "  'pixel490',\n",
       "  'pixel491',\n",
       "  'pixel492',\n",
       "  'pixel493',\n",
       "  'pixel494',\n",
       "  'pixel495',\n",
       "  'pixel496',\n",
       "  'pixel497',\n",
       "  'pixel498',\n",
       "  'pixel499',\n",
       "  'pixel500',\n",
       "  'pixel501',\n",
       "  'pixel502',\n",
       "  'pixel503',\n",
       "  'pixel504',\n",
       "  'pixel505',\n",
       "  'pixel506',\n",
       "  'pixel507',\n",
       "  'pixel508',\n",
       "  'pixel509',\n",
       "  'pixel510',\n",
       "  'pixel511',\n",
       "  'pixel512',\n",
       "  'pixel513',\n",
       "  'pixel514',\n",
       "  'pixel515',\n",
       "  'pixel516',\n",
       "  'pixel517',\n",
       "  'pixel518',\n",
       "  'pixel519',\n",
       "  'pixel520',\n",
       "  'pixel521',\n",
       "  'pixel522',\n",
       "  'pixel523',\n",
       "  'pixel524',\n",
       "  'pixel525',\n",
       "  'pixel526',\n",
       "  'pixel527',\n",
       "  'pixel528',\n",
       "  'pixel529',\n",
       "  'pixel530',\n",
       "  'pixel531',\n",
       "  'pixel532',\n",
       "  'pixel533',\n",
       "  'pixel534',\n",
       "  'pixel535',\n",
       "  'pixel536',\n",
       "  'pixel537',\n",
       "  'pixel538',\n",
       "  'pixel539',\n",
       "  'pixel540',\n",
       "  'pixel541',\n",
       "  'pixel542',\n",
       "  'pixel543',\n",
       "  'pixel544',\n",
       "  'pixel545',\n",
       "  'pixel546',\n",
       "  'pixel547',\n",
       "  'pixel548',\n",
       "  'pixel549',\n",
       "  'pixel550',\n",
       "  'pixel551',\n",
       "  'pixel552',\n",
       "  'pixel553',\n",
       "  'pixel554',\n",
       "  'pixel555',\n",
       "  'pixel556',\n",
       "  'pixel557',\n",
       "  'pixel558',\n",
       "  'pixel559',\n",
       "  'pixel560',\n",
       "  'pixel561',\n",
       "  'pixel562',\n",
       "  'pixel563',\n",
       "  'pixel564',\n",
       "  'pixel565',\n",
       "  'pixel566',\n",
       "  'pixel567',\n",
       "  'pixel568',\n",
       "  'pixel569',\n",
       "  'pixel570',\n",
       "  'pixel571',\n",
       "  'pixel572',\n",
       "  'pixel573',\n",
       "  'pixel574',\n",
       "  'pixel575',\n",
       "  'pixel576',\n",
       "  'pixel577',\n",
       "  'pixel578',\n",
       "  'pixel579',\n",
       "  'pixel580',\n",
       "  'pixel581',\n",
       "  'pixel582',\n",
       "  'pixel583',\n",
       "  'pixel584',\n",
       "  'pixel585',\n",
       "  'pixel586',\n",
       "  'pixel587',\n",
       "  'pixel588',\n",
       "  'pixel589',\n",
       "  'pixel590',\n",
       "  'pixel591',\n",
       "  'pixel592',\n",
       "  'pixel593',\n",
       "  'pixel594',\n",
       "  'pixel595',\n",
       "  'pixel596',\n",
       "  'pixel597',\n",
       "  'pixel598',\n",
       "  'pixel599',\n",
       "  'pixel600',\n",
       "  'pixel601',\n",
       "  'pixel602',\n",
       "  'pixel603',\n",
       "  'pixel604',\n",
       "  'pixel605',\n",
       "  'pixel606',\n",
       "  'pixel607',\n",
       "  'pixel608',\n",
       "  'pixel609',\n",
       "  'pixel610',\n",
       "  'pixel611',\n",
       "  'pixel612',\n",
       "  'pixel613',\n",
       "  'pixel614',\n",
       "  'pixel615',\n",
       "  'pixel616',\n",
       "  'pixel617',\n",
       "  'pixel618',\n",
       "  'pixel619',\n",
       "  'pixel620',\n",
       "  'pixel621',\n",
       "  'pixel622',\n",
       "  'pixel623',\n",
       "  'pixel624',\n",
       "  'pixel625',\n",
       "  'pixel626',\n",
       "  'pixel627',\n",
       "  'pixel628',\n",
       "  'pixel629',\n",
       "  'pixel630',\n",
       "  'pixel631',\n",
       "  'pixel632',\n",
       "  'pixel633',\n",
       "  'pixel634',\n",
       "  'pixel635',\n",
       "  'pixel636',\n",
       "  'pixel637',\n",
       "  'pixel638',\n",
       "  'pixel639',\n",
       "  'pixel640',\n",
       "  'pixel641',\n",
       "  'pixel642',\n",
       "  'pixel643',\n",
       "  'pixel644',\n",
       "  'pixel645',\n",
       "  'pixel646',\n",
       "  'pixel647',\n",
       "  'pixel648',\n",
       "  'pixel649',\n",
       "  'pixel650',\n",
       "  'pixel651',\n",
       "  'pixel652',\n",
       "  'pixel653',\n",
       "  'pixel654',\n",
       "  'pixel655',\n",
       "  'pixel656',\n",
       "  'pixel657',\n",
       "  'pixel658',\n",
       "  'pixel659',\n",
       "  'pixel660',\n",
       "  'pixel661',\n",
       "  'pixel662',\n",
       "  'pixel663',\n",
       "  'pixel664',\n",
       "  'pixel665',\n",
       "  'pixel666',\n",
       "  'pixel667',\n",
       "  'pixel668',\n",
       "  'pixel669',\n",
       "  'pixel670',\n",
       "  'pixel671',\n",
       "  'pixel672',\n",
       "  'pixel673',\n",
       "  'pixel674',\n",
       "  'pixel675',\n",
       "  'pixel676',\n",
       "  'pixel677',\n",
       "  'pixel678',\n",
       "  'pixel679',\n",
       "  'pixel680',\n",
       "  'pixel681',\n",
       "  'pixel682',\n",
       "  'pixel683',\n",
       "  'pixel684',\n",
       "  'pixel685',\n",
       "  'pixel686',\n",
       "  'pixel687',\n",
       "  'pixel688',\n",
       "  'pixel689',\n",
       "  'pixel690',\n",
       "  'pixel691',\n",
       "  'pixel692',\n",
       "  'pixel693',\n",
       "  'pixel694',\n",
       "  'pixel695',\n",
       "  'pixel696',\n",
       "  'pixel697',\n",
       "  'pixel698',\n",
       "  'pixel699',\n",
       "  'pixel700',\n",
       "  'pixel701',\n",
       "  'pixel702',\n",
       "  'pixel703',\n",
       "  'pixel704',\n",
       "  'pixel705',\n",
       "  'pixel706',\n",
       "  'pixel707',\n",
       "  'pixel708',\n",
       "  'pixel709',\n",
       "  'pixel710',\n",
       "  'pixel711',\n",
       "  'pixel712',\n",
       "  'pixel713',\n",
       "  'pixel714',\n",
       "  'pixel715',\n",
       "  'pixel716',\n",
       "  'pixel717',\n",
       "  'pixel718',\n",
       "  'pixel719',\n",
       "  'pixel720',\n",
       "  'pixel721',\n",
       "  'pixel722',\n",
       "  'pixel723',\n",
       "  'pixel724',\n",
       "  'pixel725',\n",
       "  'pixel726',\n",
       "  'pixel727',\n",
       "  'pixel728',\n",
       "  'pixel729',\n",
       "  'pixel730',\n",
       "  'pixel731',\n",
       "  'pixel732',\n",
       "  'pixel733',\n",
       "  'pixel734',\n",
       "  'pixel735',\n",
       "  'pixel736',\n",
       "  'pixel737',\n",
       "  'pixel738',\n",
       "  'pixel739',\n",
       "  'pixel740',\n",
       "  'pixel741',\n",
       "  'pixel742',\n",
       "  'pixel743',\n",
       "  'pixel744',\n",
       "  'pixel745',\n",
       "  'pixel746',\n",
       "  'pixel747',\n",
       "  'pixel748',\n",
       "  'pixel749',\n",
       "  'pixel750',\n",
       "  'pixel751',\n",
       "  'pixel752',\n",
       "  'pixel753',\n",
       "  'pixel754',\n",
       "  'pixel755',\n",
       "  'pixel756',\n",
       "  'pixel757',\n",
       "  'pixel758',\n",
       "  'pixel759',\n",
       "  'pixel760',\n",
       "  'pixel761',\n",
       "  'pixel762',\n",
       "  'pixel763',\n",
       "  'pixel764',\n",
       "  'pixel765',\n",
       "  'pixel766',\n",
       "  'pixel767',\n",
       "  'pixel768',\n",
       "  'pixel769',\n",
       "  'pixel770',\n",
       "  'pixel771',\n",
       "  'pixel772',\n",
       "  'pixel773',\n",
       "  'pixel774',\n",
       "  'pixel775',\n",
       "  'pixel776',\n",
       "  'pixel777',\n",
       "  'pixel778',\n",
       "  'pixel779',\n",
       "  'pixel780',\n",
       "  'pixel781',\n",
       "  'pixel782',\n",
       "  'pixel783',\n",
       "  'pixel784'],\n",
       " 'target_names': ['class'],\n",
       " 'DESCR': \"**Author**: Yann LeCun, Corinna Cortes, Christopher J.C. Burges  \\n**Source**: [MNIST Website](http://yann.lecun.com/exdb/mnist/) - Date unknown  \\n**Please cite**:  \\n\\nThe MNIST database of handwritten digits with 784 features, raw data available at: http://yann.lecun.com/exdb/mnist/. It can be split in a training set of the first 60,000 examples, and a test set of 10,000 examples  \\n\\nIt is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image. It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting. The original black and white (bilevel) images from NIST were size normalized to fit in a 20x20 pixel box while preserving their aspect ratio. The resulting images contain grey levels as a result of the anti-aliasing technique used by the normalization algorithm. the images were centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field.  \\n\\nWith some classification methods (particularly template-based methods, such as SVM and K-nearest neighbors), the error rate improves when the digits are centered by bounding box rather than center of mass. If you do this kind of pre-processing, you should report it in your publications. The MNIST database was constructed from NIST's NIST originally designated SD-3 as their training set and SD-1 as their test set. However, SD-3 is much cleaner and easier to recognize than SD-1. The reason for this can be found on the fact that SD-3 was collected among Census Bureau employees, while SD-1 was collected among high-school students. Drawing sensible conclusions from learning experiments requires that the result be independent of the choice of training set and test among the complete set of samples. Therefore it was necessary to build a new database by mixing NIST's datasets.  \\n\\nThe MNIST training set is composed of 30,000 patterns from SD-3 and 30,000 patterns from SD-1. Our test set was composed of 5,000 patterns from SD-3 and 5,000 patterns from SD-1. The 60,000 pattern training set contained examples from approximately 250 writers. We made sure that the sets of writers of the training set and test set were disjoint. SD-1 contains 58,527 digit images written by 500 different writers. In contrast to SD-3, where blocks of data from each writer appeared in sequence, the data in SD-1 is scrambled. Writer identities for SD-1 is available and we used this information to unscramble the writers. We then split SD-1 in two: characters written by the first 250 writers went into our new training set. The remaining 250 writers were placed in our test set. Thus we had two sets with nearly 30,000 examples each. The new training set was completed with enough examples from SD-3, starting at pattern # 0, to make a full set of 60,000 training patterns. Similarly, the new test set was completed with SD-3 examples starting at pattern # 35,000 to make a full set with 60,000 test patterns. Only a subset of 10,000 test images (5,000 from SD-1 and 5,000 from SD-3) is available on this site. The full 60,000 sample training set is available.\\n\\nDownloaded from openml.org.\",\n",
       " 'details': {'id': '554',\n",
       "  'name': 'mnist_784',\n",
       "  'version': '1',\n",
       "  'description_version': '2',\n",
       "  'format': 'ARFF',\n",
       "  'creator': ['Yann LeCun', 'Corinna Cortes', 'Christopher J.C. Burges'],\n",
       "  'upload_date': '2014-09-29T03:28:38',\n",
       "  'language': 'English',\n",
       "  'licence': 'Public',\n",
       "  'url': 'https://api.openml.org/data/v1/download/52667/mnist_784.arff',\n",
       "  'parquet_url': 'https://openml1.win.tue.nl/datasets/0000/0554/dataset_554.pq',\n",
       "  'file_id': '52667',\n",
       "  'default_target_attribute': 'class',\n",
       "  'tag': ['AzurePilot',\n",
       "   'OpenML-CC18',\n",
       "   'OpenML100',\n",
       "   'study_1',\n",
       "   'study_123',\n",
       "   'study_41',\n",
       "   'study_99',\n",
       "   'vision'],\n",
       "  'visibility': 'public',\n",
       "  'minio_url': 'https://openml1.win.tue.nl/datasets/0000/0554/dataset_554.pq',\n",
       "  'status': 'active',\n",
       "  'processing_date': '2020-11-20 20:12:09',\n",
       "  'md5_checksum': '0298d579eb1b86163de7723944c7e495'},\n",
       " 'url': 'https://www.openml.org/d/554'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Author**: Yann LeCun, Corinna Cortes, Christopher J.C. Burges  \n",
      "**Source**: [MNIST Website](http://yann.lecun.com/exdb/mnist/) - Date unknown  \n",
      "**Please cite**:  \n",
      "\n",
      "The MNIST database of handwritten digits with 784 features, raw data available at: http://yann.lecun.com/exdb/mnist/. It can be split in a training set of the first 60,000 examples, and a test set of 10,000 examples  \n",
      "\n",
      "It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image. It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting. The original black and white (bilevel) images from NIST were size normalized to fit in a 20x20 pixel box while preserving their aspect ratio. The resulting images contain grey levels as a result of the anti-aliasing technique used by the normalization algorithm. the images were centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field.  \n",
      "\n",
      "With some classification methods (particularly template-based methods, such as SVM and K-nearest neighbors), the error rate improves when the digits are centered by bounding box rather than center of mass. If you do this kind of pre-processing, you should report it in your publications. The MNIST database was constructed from NIST's NIST originally designated SD-3 as their training set and SD-1 as their test set. However, SD-3 is much cleaner and easier to recognize than SD-1. The reason for this can be found on the fact that SD-3 was collected among Census Bureau employees, while SD-1 was collected among high-school students. Drawing sensible conclusions from learning experiments requires that the result be independent of the choice of training set and test among the complete set of samples. Therefore it was necessary to build a new database by mixing NIST's datasets.  \n",
      "\n",
      "The MNIST training set is composed of 30,000 patterns from SD-3 and 30,000 patterns from SD-1. Our test set was composed of 5,000 patterns from SD-3 and 5,000 patterns from SD-1. The 60,000 pattern training set contained examples from approximately 250 writers. We made sure that the sets of writers of the training set and test set were disjoint. SD-1 contains 58,527 digit images written by 500 different writers. In contrast to SD-3, where blocks of data from each writer appeared in sequence, the data in SD-1 is scrambled. Writer identities for SD-1 is available and we used this information to unscramble the writers. We then split SD-1 in two: characters written by the first 250 writers went into our new training set. The remaining 250 writers were placed in our test set. Thus we had two sets with nearly 30,000 examples each. The new training set was completed with enough examples from SD-3, starting at pattern # 0, to make a full set of 60,000 training patterns. Similarly, the new test set was completed with SD-3 examples starting at pattern # 35,000 to make a full set with 60,000 test patterns. Only a subset of 10,000 test images (5,000 from SD-1 and 5,000 from SD-3) is available on this site. The full 60,000 sample training set is available.\n",
      "\n",
      "Downloaded from openml.org.\n"
     ]
    }
   ],
   "source": [
    "# description of dataset\n",
    "print(mnist.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataframe from the original dataset\n",
    "- This will assist us with:\n",
    "    1. Viewing the data and its attributes\n",
    "    2. Efficiently clean the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(data=mnist.data)\n",
    "y = pd.DataFrame(data=mnist.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the data\n",
    "- View some of the attributes of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  774  775  776  777  \\\n",
       "0    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "1    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "2    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "3    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "4    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
       "\n",
       "   778  779  780  781  782  783  \n",
       "0    0    0    0    0    0    0  \n",
       "1    0    0    0    0    0    0  \n",
       "2    0    0    0    0    0    0  \n",
       "3    0    0    0    0    0    0  \n",
       "4    0    0    0    0    0    0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  5\n",
       "1  0\n",
       "2  4\n",
       "3  1\n",
       "4  9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>70000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.197414</td>\n",
       "      <td>0.099543</td>\n",
       "      <td>0.046629</td>\n",
       "      <td>0.016614</td>\n",
       "      <td>0.012957</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.991206</td>\n",
       "      <td>4.256304</td>\n",
       "      <td>2.783732</td>\n",
       "      <td>1.561822</td>\n",
       "      <td>1.553796</td>\n",
       "      <td>0.320889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0        1        2        3        4        5        6        7    \\\n",
       "count  70000.0  70000.0  70000.0  70000.0  70000.0  70000.0  70000.0  70000.0   \n",
       "mean       0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "           8        9    ...           774           775           776  \\\n",
       "count  70000.0  70000.0  ...  70000.000000  70000.000000  70000.000000   \n",
       "mean       0.0      0.0  ...      0.197414      0.099543      0.046629   \n",
       "std        0.0      0.0  ...      5.991206      4.256304      2.783732   \n",
       "min        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
       "25%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
       "50%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
       "75%        0.0      0.0  ...      0.000000      0.000000      0.000000   \n",
       "max        0.0      0.0  ...    254.000000    254.000000    253.000000   \n",
       "\n",
       "                777           778           779      780      781      782  \\\n",
       "count  70000.000000  70000.000000  70000.000000  70000.0  70000.0  70000.0   \n",
       "mean       0.016614      0.012957      0.001714      0.0      0.0      0.0   \n",
       "std        1.561822      1.553796      0.320889      0.0      0.0      0.0   \n",
       "min        0.000000      0.000000      0.000000      0.0      0.0      0.0   \n",
       "25%        0.000000      0.000000      0.000000      0.0      0.0      0.0   \n",
       "50%        0.000000      0.000000      0.000000      0.0      0.0      0.0   \n",
       "75%        0.000000      0.000000      0.000000      0.0      0.0      0.0   \n",
       "max      253.000000    254.000000     62.000000      0.0      0.0      0.0   \n",
       "\n",
       "           783  \n",
       "count  70000.0  \n",
       "mean       0.0  \n",
       "std        0.0  \n",
       "min        0.0  \n",
       "25%        0.0  \n",
       "50%        0.0  \n",
       "75%        0.0  \n",
       "max        0.0  \n",
       "\n",
       "[8 rows x 784 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7877\n",
       "7    7293\n",
       "3    7141\n",
       "2    6990\n",
       "9    6958\n",
       "0    6903\n",
       "6    6876\n",
       "8    6825\n",
       "4    6824\n",
       "5    6313\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What we found:\n",
    "1. There are 0 value columns in every instance\n",
    "1. Labels are integers in the range 0-9 inclusive\n",
    "# What we can do:\n",
    "1. Train model on subset of attributes that have atleast 1 non-zero value throughout all instances\n",
    "1. Train classification as all instances are digits\n",
    "# Operation\n",
    "1. Remove columns whose max is there min\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns: 65\n",
      "New shape of training dataset: (70000, 719)\n"
     ]
    }
   ],
   "source": [
    "dropped_columns = []\n",
    "for column in X.columns:\n",
    "    if X[column].max() == X[column].min():\n",
    "        dropped_columns.append(column)\n",
    "X.drop(dropped_columns, axis=1, inplace=True)\n",
    "print('Dropped columns:', len(dropped_columns))\n",
    "print('New shape of training dataset:', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confirm that there are no faulty values in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in X.columns:\n",
    "    if X[column].isnull().any():\n",
    "        print('Null value detected in feature: ', column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hooray! No nulls detected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_X = {}\n",
    "max_X = {}\n",
    "for column in X.columns:\n",
    "    min_X[column] = X[column].min()\n",
    "    max_X[column] = X[column].max()\n",
    "    X[column] = (X[column] - X[column].min())/(X[column].max() - X[column].min())\n",
    "X = X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>709</th>\n",
       "      <th>710</th>\n",
       "      <th>711</th>\n",
       "      <th>712</th>\n",
       "      <th>713</th>\n",
       "      <th>714</th>\n",
       "      <th>715</th>\n",
       "      <th>716</th>\n",
       "      <th>717</th>\n",
       "      <th>718</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 719 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1    2    3    4    5    6    7    8    9    ...  709  710  711  712  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   713  714  715  716  717  718  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 719 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>709</th>\n",
       "      <th>710</th>\n",
       "      <th>711</th>\n",
       "      <th>712</th>\n",
       "      <th>713</th>\n",
       "      <th>714</th>\n",
       "      <th>715</th>\n",
       "      <th>716</th>\n",
       "      <th>717</th>\n",
       "      <th>718</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "      <td>70000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002625</td>\n",
       "      <td>0.002312</td>\n",
       "      <td>0.001879</td>\n",
       "      <td>0.001308</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.003794</td>\n",
       "      <td>0.004961</td>\n",
       "      <td>0.003780</td>\n",
       "      <td>0.003780</td>\n",
       "      <td>0.003780</td>\n",
       "      <td>0.004903</td>\n",
       "      <td>0.005605</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.011573</td>\n",
       "      <td>0.012764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044066</td>\n",
       "      <td>0.041184</td>\n",
       "      <td>0.037055</td>\n",
       "      <td>0.031066</td>\n",
       "      <td>0.023587</td>\n",
       "      <td>0.016757</td>\n",
       "      <td>0.011003</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>0.006117</td>\n",
       "      <td>0.005176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 719 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2             3             4    \\\n",
       "count  70000.000000  70000.000000  70000.000000  70000.000000  70000.000000   \n",
       "mean       0.000016      0.000026      0.000014      0.000014      0.000014   \n",
       "std        0.003794      0.004961      0.003780      0.003780      0.003780   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                5             6             7             8             9    \\\n",
       "count  70000.000000  70000.000000  70000.000000  70000.000000  70000.000000   \n",
       "mean       0.000028      0.000048      0.000091      0.000170      0.000245   \n",
       "std        0.004903      0.005605      0.007990      0.011573      0.012764   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       ...           709           710           711           712  \\\n",
       "count  ...  70000.000000  70000.000000  70000.000000  70000.000000   \n",
       "mean   ...      0.002625      0.002312      0.001879      0.001308   \n",
       "std    ...      0.044066      0.041184      0.037055      0.031066   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                713           714           715           716           717  \\\n",
       "count  70000.000000  70000.000000  70000.000000  70000.000000  70000.000000   \n",
       "mean       0.000777      0.000392      0.000184      0.000066      0.000051   \n",
       "std        0.023587      0.016757      0.011003      0.006173      0.006117   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                718  \n",
       "count  70000.000000  \n",
       "mean       0.000028  \n",
       "std        0.005176  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 719 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn Models\n",
    "- Random Forrest classifier\n",
    "- K-nearest neighbor\n",
    "# Random Forrest Classifier\n",
    "- Hyperparameters:\n",
    "    1. Node Size\n",
    "    1. Number of Nodes\n",
    "    1. Number of features sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# X_train = X[:60000]\n",
    "# X_test = X[60000:70000]\n",
    "# y_train = y[:60000]\n",
    "# y_test = y[60000:70000]\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1428)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60004, 719)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.get_params()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q0/46rg_8k54v9fz0gpl1y4k0yh0000gn/T/ipykernel_84279/2789652163.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  clf.fit(X_test, y_test)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test random forrest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, y_pred, normalize='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0         1        2         3         4         5         6  \\\n",
      "0  0.10004  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000   \n",
      "1  0.00000  0.108944  0.00000  0.000000  0.000000  0.000000  0.000000   \n",
      "2  0.00000  0.000000  0.10014  0.000000  0.000000  0.000000  0.000000   \n",
      "3  0.00000  0.000000  0.00000  0.106443  0.000000  0.000000  0.000000   \n",
      "4  0.00000  0.000000  0.00000  0.000000  0.098039  0.000000  0.000000   \n",
      "5  0.00000  0.000000  0.00000  0.000000  0.000000  0.091937  0.000000   \n",
      "6  0.00000  0.000000  0.00000  0.000000  0.000000  0.000000  0.097739   \n",
      "7  0.00000  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000   \n",
      "8  0.00000  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000   \n",
      "9  0.00000  0.000000  0.00000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "         7         8        9  \n",
      "0  0.00000  0.000000  0.00000  \n",
      "1  0.00000  0.000000  0.00000  \n",
      "2  0.00000  0.000000  0.00000  \n",
      "3  0.00000  0.000000  0.00000  \n",
      "4  0.00000  0.000000  0.00000  \n",
      "5  0.00000  0.000000  0.00000  \n",
      "6  0.00000  0.000000  0.00000  \n",
      "7  0.10044  0.000000  0.00000  \n",
      "8  0.00000  0.095938  0.00000  \n",
      "9  0.00000  0.000000  0.10034  \n"
     ]
    }
   ],
   "source": [
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning for Random Forrest Classifier\n",
    "- Gridsearch to find the best hyper parameters for random forrest classifier\n",
    "1. Node Size\n",
    "1. Number of Nodes\n",
    "1. Number of features sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    'n_estimators': [10,50,100,250],\n",
    "    'max_depth': [5,10,20],\n",
    "    'class_weight': [None, {0:1, 1:5}, {0:1, 1:10}, {0:1, 1:25}]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_svc = GridSearchCV(clf, param_grid=search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noahcampise/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "/Users/noahcampise/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgrid_svc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/joblib/parallel.py:1051\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1049\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1051\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1055\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/joblib/parallel.py:864\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 864\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    865\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/joblib/parallel.py:782\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    781\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 782\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/joblib/parallel.py:263\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/joblib/parallel.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:473\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    462\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    463\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    465\u001b[0m ]\n\u001b[1;32m    467\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 473\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/joblib/parallel.py:1051\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1049\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1051\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1055\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/joblib/parallel.py:864\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 864\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    865\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/joblib/parallel.py:782\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    781\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 782\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/joblib/parallel.py:263\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/joblib/parallel.py:263\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 263\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    264\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/parallel.py:123\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:184\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    182\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[0;32m--> 184\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    186\u001b[0m     tree\u001b[38;5;241m.\u001b[39mfit(X, y, sample_weight\u001b[38;5;241m=\u001b[39msample_weight, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/tree/_classes.py:889\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    861\u001b[0m \n\u001b[1;32m    862\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 889\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    895\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/tree/_classes.py:379\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    370\u001b[0m         splitter,\n\u001b[1;32m    371\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    377\u001b[0m     )\n\u001b[0;32m--> 379\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grid_svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K nearest neighbor \n",
    "- Hyperparameters:\n",
    "    1. K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noahcampise/anaconda3/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:215: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9739895958383353"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = neigh.predict(X_test)\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, y_pred, normalize='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K nearest neighbors all day baby"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'leaf_size': 30,\n",
       " 'metric': 'minkowski',\n",
       " 'metric_params': None,\n",
       " 'n_jobs': None,\n",
       " 'n_neighbors': 3,\n",
       " 'p': 2,\n",
       " 'weights': 'uniform'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
